---
title: "final project"
output: html_document
---

```{r}
#error metrics -- Confusion Matrix
err_metric=function(CM)
{
  TN =CM[1,1]
  TP =CM[2,2]
  FP =CM[1,2]
  FN =CM[2,1]
  precision =(TP)/(TP+FP)
  recall_score =(TP)/(TP+FN)
 
  f1_score=2*((precision*recall_score)/(precision+recall_score))
  accuracy_model  =(TP+TN)/(TP+TN+FP+FN)
  False_positive_rate =(FP)/(FP+TN)
  False_negative_rate =(FN)/(FN+TP)
 
  print(paste("Precision value of the model: ",round(precision,2)))
  print(paste("Accuracy of the model: ",round(accuracy_model,2)))
  print(paste("Recall value of the model: ",round(recall_score,2)))
  print(paste("False Positive rate of the model: ",round(False_positive_rate,2)))
 
  print(paste("False Negative rate of the model: ",round(False_negative_rate,2)))
 
  print(paste("f1 score of the model: ",round(f1_score,2)))
}
```


```{r,message=F,warning=F}
library('tidyverse')
library('ggplot2')
library(DiffXTables)
library(lattice)
library(caret)
library(MLmetrics)
library(reticulate)
library(e1071)
library(kknn)
library(rpart)
library(ROSE)
library(MASS)
library(keras)
library(BBmisc)
library(reticulate)
library(pracma)
library(DMwR)
library(fastDummies)
library(stringr)
library(glmnet)
```

```{r}
feature_name_adult = c('AGE','WORKCLASS','FNLWGT','EDUCATION','EDUCATIONNUM','MARITALSTATUS','OCCUPATION','RELATIONSHIP','RACE','SEX','CAPITALGAIN','CAPITALLOSS','HOURSPERWEEK','NATIVECOUNTRY','ABOVE50K')
data_adult = read.table("C:\\Users\\xx958\\OneDrive\\桌面\\nycu 碩一_上\\數據科學\\adult\\adult.data",head=F,sep = ",",col.names=feature_name_adult)
class_variable_adult = c('WORKCLASS','EDUCATION','MARITALSTATUS','OCCUPATION','RELATIONSHIP','RACE','SEX','NATIVECOUNTRY','ABOVE50K')
index_class_variable_adult = c(2,4,6,7,8,9,10,14,15)
```

since this data miss value is use '?' express ,so we use NA replace '?'
```{r}
for (i in feature_name_adult){
    if (sum(data_adult[[i]] == ' ?')>0){
      data_adult[data_adult[[i]] == ' ?',][[i]] =NA
  }
}

```

## 將類別資料轉成numeric型態，並從Dataframe 轉成 tibble
```{r}
for (i in class_variable_adult){
  data_adult[[i]]=as.numeric(as.factor(data_adult[[i]]))
}
# as.numeric
data_adult$ABOVE50K = data_adult$ABOVE50K-1
```

# dummy variable (one hat encoding)
```{r}
for (i in class_variable_adult){
  data_adult[[i]] = str_trim(data_adult[[i]])
  data_adult[[i]] = gsub(data_adult[[i]], pattern ="-", replacement = "_")
  data_adult[[i]] = gsub(data_adult[[i]], pattern ="&", replacement = "_")
}
dummy_data_adult <- dummy_cols(data_adult[,-15],remove_first_dummy =T)[,-index_class_variable_adult]
dummy_data_adult['ABOVE50K'] =as.numeric(as.factor(data_adult[,15]))-1
data_adult = dummy_data_adult
names(data_adult)[82]<-paste("NATIVECOUNTRY_Outlying_US")
```


## find NA and remove then
```{r}
colSums(is.na(data_adult))
```

```{r}
miss_value = which(is.na(data_adult$WORKCLASS)==1)
data_adult = data_adult[-miss_value,]

miss_value = which(is.na(data_adult$OCCUPATION)==1)
data_adult = data_adult[-miss_value,]

miss_value = which(is.na(data_adult$NATIVECOUNTRY)==1)
data_adult = data_adult[-miss_value,]

```

# imbalance data
```{r}
data_adult%>%
  ggplot(aes(x=ABOVE50K))+
  geom_bar()+
  geom_text(stat='count',aes(label=..count..),vjust=1.6,color="white", size=3.5)

a = table(data_adult$ABOVE50K)

pie(a)
```

# split train set and test set
```{r}
p=0.8
index <- createDataPartition(data_adult$ABOVE50K, p = p, list = F)
train <- data_adult[index, ]
test <- data_adult[-index, ]
#train[1:95]<-normalize(train[1:95])
#test[1:95]<-normalize(test[1:95])
```

Lasso feature selection
```{r}
cv.lasso <- cv.glmnet(as.matrix(train[,1:14]), train[,15], family='binomial', alpha=1, parallel=TRUE, standardize=TRUE, type.measure='auc')

df_coef <- round(as.matrix(coef(cv.lasso, s=cv.lasso$lambda.min)), 2)
df_coef[df_coef[, 1] != 0, ]
```

# logistic regression
```{r}
# weight 
weight = rep(1,dim(train)[1])
weight[train$ABOVE50K==1]=3

logistic_regression = glm(ABOVE50K ~ .,data=train , family='binomial' , weights = weight)
summary(logistic_regression)
logistic_predict=predict(logistic_regression, test[,-15])
labels <- ifelse(logistic_predict > 0.5, 1, 0)
cm=table('real'=test$ABOVE50K,'predict'=labels)
err_metric(cm)
# confusionMatrix(reference = as.factor(test$ABOVE50K),data = as.factor(labels), mode='everything', positive='1')
```

# Over Sampling
improve the f1-score from 0.4 to 0.6 and the Accuracy not decline
```{r}
number_max = max(table(train$ABOVE50K))
over <- ovun.sample(ABOVE50K ~ . , data = train, method = "over" ,N =number_max*2)$data
logistic_regression = glm(ABOVE50K~. ,data=over , family='binomial')
summary(logistic_regression)
logistic_predict=predict(logistic_regression, test[,-96])
labels <- ifelse(logistic_predict > 0.5, 1, 0)
cm=table('real'=test$ABOVE50K,'predict'=labels)
err_metric(cm)
```

# Under Sampling
have same effect
```{r}
number_min = min(table(train$ABOVE50K))
under <- ovun.sample(ABOVE50K~., data=train, method = "under", N = number_min*2)$data
logistic_regression = glm(ABOVE50K~. ,data=under , family='binomial')
# summary(logistic_regression)
logistic_predict=predict(logistic_regression, test[,-96])
labels <- ifelse(logistic_predict > 0.5, 1, 0)
cm=table('real'=test$ABOVE50K,'predict'=labels)
err_metric(cm)
```
# Both
```{r}
average_number =  mean(table(train$ABOVE50K))
both <- ovun.sample(ABOVE50K~., data=train, method = "both",
                    p = 0.5,
                    N = round(average_number))$data
logistic_regression = glm(ABOVE50K~. ,data=both , family='binomial')
# summary(logistic_regression)
logistic_predict=predict(logistic_regression, test[,-15])
labels <- ifelse(logistic_predict > 0.5, 1, 0)
cm=table('real'=test$ABOVE50K,'predict'=labels)
err_metric(cm)
```
# ROSE Function
```{r}
rose  = ROSE(ABOVE50K~., data = train, N = average_number)$data
logistic_regression = glm(ABOVE50K~. ,data=rose , family='binomial')
# summary(logistic_regression)
logistic_predict=predict(logistic_regression, test[,-15])
labels <- ifelse(logistic_predict > 0.5, 1, 0)
cm=table('real'=test$ABOVE50K,'predict'=labels)
err_metric(cm)
```

# deep learning
```{r}
modeldeep <- keras_model_sequential()
modeldeep %>%
    layer_dense(units=32, activation = "relu",
              kernel_initializer = "he_normal",input_shape =c(95))%>%
    layer_dropout(rate=0.2)%>%
    layer_dense(units=64, activation = "relu",
              kernel_initializer = "he_normal")%>%
    layer_dropout(rate=0.4)%>%
        layer_dense(units=2, activation = "sigmoid")
summary(modeldeep)
```

```{r}
modeldeep %>%
  compile(loss="binary_crossentropy",
          optimizer="adam",
          metric="accuracy")

trainlabel<-to_categorical(train[,96])
testlabel<-to_categorical(test[,96])
train<-normalize(train)
test<-normalize(test)
train =as.matrix(train)
test =as.matrix(test)

history<- modeldeep %>%
  fit(train[,c(1:95)],trainlabel,batch_size=5, validation_split=0.2 ,epochs =20)

# save_model_hdf5(modeldeep,"modeldeep.h5")
modeldeep<-load_model_hdf5("modeldeep.h5")

pred<-  modeldeep %>%
  predict_classes(test[,c(1:95)])
cm=table('real'=testlabel[,2],'predict'=pred)
err_metric(cm)
```

```{r}
modeldeep1 <- keras_model_sequential()
modeldeep1 %>%
    layer_dense(units=32, activation = "relu",
              kernel_initializer = "he_normal",input_shape =c(95))%>%
    layer_dropout(rate=0.2)%>%
    layer_dense(units=64, activation = "relu",
              kernel_initializer = "he_normal")%>%
    layer_dropout(rate=0.4)%>%
    layer_dense(units=128, activation = "relu",
              kernel_initializer = "he_normal")%>%
    layer_dropout(rate=0.4)%>%
        layer_dense(units=2, activation = "sigmoid")
modeldeep1 %>%
  compile(loss="binary_crossentropy",
          optimizer="SGD",
          metric="accuracy")

summary(modeldeep1)
```

```{r}
history1<- modeldeep1 %>%
  fit(train[,c(1:95)],trainlabel,batch_size=5, validation_split=0.2 , class_weight=list("0"=1,"1"=a[1]/a[2]),epochs =30)

# save_model_hdf5(modeldeep1,"modeldeep1.h5")
# modeldeep1<-load_model_hdf5("modeldeep1.h5")

pred<-  modeldeep1 %>%
  predict_classes(test[,c(1:95)])
cm=table('real'=testlabel[,2],'predict'=pred)
err_metric(cm)
```

```{r}
# model
modeldeep2 <- keras_model_sequential()
modeldeep2 %>%
    layer_dense(units=32, activation = "relu",
              kernel_initializer = "he_normal",input_shape =c(2))%>%
    layer_dropout(rate=0.2)%>%
    layer_dense(units=64, activation = "relu",
              kernel_initializer = "he_normal")%>%
    layer_dropout(rate=0.4)%>%
        layer_dense(units=2, activation = "sigmoid")
modeldeep2 %>%
  compile(loss="binary_crossentropy",
          optimizer="adam",
          metric="accuracy")

trainlabel<-to_categorical(train[,96])
train[,1:95]<-normalize(train[,1:95])
train =as.matrix(train)

# pca train
train = data.frame(train)
pca = prcomp(~.,data=train[,1:95])
top2_pca = pca$x[,1:2]
top2_pca = as.matrix(top2_pca)
# fit model
history2<- modeldeep2 %>%
  fit(top2_pca,trainlabel,batch_size=5, validation_split=0.2,class_weight=list("0"=1,"1"=a[1]/a[2]),epochs =30)

x = seq(min(top2_pca[,1]),max(top2_pca[,1]),0.05)
y = seq(min(top2_pca[,2]),max(top2_pca[,2]),0.05)
xx = meshgrid(x,y)
xx = matrix(c(xx$X,xx$Y),ncol=2)
pred_grid<-  modeldeep2 %>%
  predict_classes(xx)
# plot
xx = data.frame(xx)
xx['c'] = (pred_grid)

top2_pca = data.frame(top2_pca)
top2_pca%>%
  ggplot()+
  geom_point(aes(PC1,PC2,col = as.factor(trainlabel[,2])))+
  geom_point(aes(X1,X2,col=as.factor(xx$c)),alpha=0.03,data = xx)
```

```{r}
logistic_accuracy_label = c('None'=0.81,'Up'=0.8,'Down'=0.8)
logistic_F1_score_label = c('None'=0.47,'Up'=0.62,'Down'=0.62)

plot(seq(along=logistic_accuracy_label), logistic_accuracy_label,xlab='',axes=FALSE,ylab='score',ylim=c(0,1),col='red',type='b')
points(x=seq(along=logistic_F1_score_label), y=logistic_F1_score_label,col='blue',type='b')
points(x=seq(along=logistic_accuracy_onehot), y=logistic_accuracy_onehot,col='green',type='b')
points(x=seq(along=logistic_F1_score_onehot), y=logistic_F1_score_onehot,col='magenta',type='b')

box(); axis(2)
axis(1, at=seq(along=logistic_accuracy_label), labels=names(logistic_accuracy_label))
legend('bottomleft', col=c("red", "blue",'green','magenta'),
       lty=c(1,1), lwd=c(2,2), 
       legend=c("label_accuracy", "label _F1_score",'one_hot_accuracy','one_hot_F1_score'))

DNN_accuracy_label = c('None'=0.84,'weight'=0.83)
DNN_F1_score_label = c('None'=0.63,'weight'=0.69)
DNN_accuracy_onehot = c('None'=0.85,'weight'=0.83)
DNN_F1_score_onehot = c('None'=0.66,'weight'=0.71)

plot(seq(along=DNN_accuracy_label), DNN_accuracy_label,xlab='',axes=FALSE,ylab='score',ylim=c(0,1),col='red',type='b')
points(x=seq(along=DNN_F1_score_label), y=DNN_F1_score_label,col='blue',type='b')
points(x=seq(along=DNN_accuracy_onehot), y=DNN_accuracy_onehot,col='green',type='b')
points(x=seq(along=DNN_F1_score_onehot), y=DNN_F1_score_onehot,col='magenta',type='b')

box(); axis(2)
axis(1, at=seq(along=DNN_accuracy_label), labels=names(DNN_accuracy_label))
legend('bottomleft', col=c("red", "blue",'green','magenta'),
       lty=c(1,1), lwd=c(2,2), 
       legend=c("label_accuracy", "label _F1_score",'one_hot_accuracy','one_hot_F1_score'))

```

